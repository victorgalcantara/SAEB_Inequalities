---
title: "lmer_multilevel"
author: "Victor G Alcantara"
date: "04/01/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r message=F,warning=FALSE, include=F}
# 0. Packages and setup -------------------------------------------------
library(tidyverse) 
library(readxl)    
library(stargazer) # for print results
library(lme4)      # for multilevel models

# Diretório com as bases de dados que iremos trabalhar guardado no objeto
wd <- "C:/Users/VictorGabriel/Documents/00_dados/"
wd_2 <- "E:/VGA/dados/EDUCACAO/"
setwd(wd_2)

# 1. Import data
load("samples_n10.RDS")
load("estruturaEscola13-17.RDS")

idhm <- read_xlsx(paste0(wd,"ATLAS DESIG/ATLAS_2013.xlsx"),sheet = 2) %>% 
  select(ANO,IDHM,Codmun7) %>% filter(ANO == 2010)
my_saeb <- my_samples[[3]] %>% select(
  ID_ALUNO,ID_ESCOLA,ID_REGIAO,ID_MUNICIPIO,ID_UF,
  ID_LOCALIZACAO,PROFICIENCIA_LP_SAEB,PROFICIENCIA_MT_SAEB,
  IN_PREENCHIMENTO_QUESTIONARIO,IN_PREENCHIMENTO_PROVA,
  regiao,fluxo,sexo,raca,raca2,trabFora,trabDom,educPai,educMae,
  CC,CE
)

data <- merge(my_saeb,estruturaEscola[[3]],by = "ID_ESCOLA")
data <- merge(data,idhm,by.x="ID_MUNICIPIO.x",by.y = "Codmun7")

# Dados do livro
school <- c(767 ,785 ,789 ,815 ,981)
n      <- c(58 ,29 ,64 ,39 ,88)
me     <- c(3.952 ,3.331 ,4.363 ,4.500 ,4.236)
var    <- c(5.298,1.524,2.957,6.088,3.362)
table_1 <- data.frame(school,n,me,var)

school    <- c(1:5)   
intercept <- c(1.230 ,2.673 ,2.707 ,2.867 ,2.319)
U0j       <- c(-1.129, 0.314 ,0.348  ,0.508 ,-0.040)
slope     <- c(.552,.199 ,.376 ,.336 ,.411)
U1j       <- c(0.177,-0.176,0.001,-0.039, 0.036)
table_2 <- data.frame(school,intercept,U0j,slope,U1j)
```


# Regressão linear com modelos hierárquicos ou multiníveis
Multilevel Linear Models (MLM)

Há dados em que os indivíduos são agrupados (clusterizados) e, portanto, estão associados (o que fere o pressuposto da independência). Nestes casos, é necessário o uso de técnicas que ponderem os efeitos entre os agrupamentos (clusters). Este é, por exemplo, o caso dos dados educacionais, nos quais os alunos estão associados às turmas, às escolas, às associações/clubes, às redes/sistemas de educação, aos distritos, etc.

Em casos de dados clusterizados (clusters designs), nosso interesse é saber quanto da variabilidade da variável de interesse é explicada pelos níveis (indivíduo e grupos). Para isso, estimamos o intercepto e os coeficientes para os indivíduos entre os grupos (total) e para os indivíduos dentro dos grupos (parcial).

Em dados com estrutura de níveis, os modelos lineares de um nível não são suficiente para compreender a variabilidade da variável de interesse. Vejamos, por exemplo, a diferença entre os modelos lineares entre os grupos e dentre os grupos com algumas escolas do SAEB:

```{r message=F,warning=FALSE}
# SAEB 2013
head(data)

# Schools
clusters_data <- data %>% group_by(ID_ESCOLA) %>% summarise(
 S_LP = var(PROFICIENCIA_LP_SAEB, na.rm = T),
 S_MT = var(PROFICIENCIA_MT_SAEB, na.rm = T),
 n = n(),
 me_LP = mean(PROFICIENCIA_LP_SAEB,na.rm=T),
 me_MT = mean(PROFICIENCIA_MT_SAEB,na.rm=T)
 )

school <- unique(data$ID_ESCOLA)
coef <- data.frame(ID_ESCOLA=NULL,b0=NULL,b1=NULL )

d <- data %>% select(ID_ESCOLA,PROFICIENCIA_LP_SAEB,CE,n) %>% filter(n > 2) %>% na.exclude()

for(i in 1:length(school)){
  cluster <- d %>% filter(ID_ESCOLA == school[i])
  if(!is_empty(cluster$ID_ESCOLA)) { # controle para escolas ausentes
  reg  <- lm(data=cluster,PROFICIENCIA_LP_SAEB ~ CE)
  b0 <- reg$coefficients[[1]]
  b1 <- reg$coefficients[[2]]
  c  <- data.frame(b0=b0,b1=b1,ID_ESCOLA=school[i])
  coef <- bind_rows(c,coef) 
  }
}

clusters <- merge(coef,clusters_data,by = "ID_ESCOLA")
data <- merge(data,clusters,by = "ID_ESCOLA")

saeb <- data %>% select(PROFICIENCIA_LP_SAEB,CE,n,ID_ESCOLA,b0,b1) %>% filter(n > 30) %>% # Escolas com mais de 30 alunos
  na.exclude() 

# Escolas selecionadas com base no contraste dos coef. de inclinação
esc_selecao <- c(23010860,23080809,27029930,26054094)

escolas <- data %>% filter(ID_ESCOLA %in% esc_selecao) %>% mutate(., Escolas = case_when(
  ID_ESCOLA == 23010860 ~ "Escola 1",
  ID_ESCOLA == 23080809 ~ "Escola 2",
  ID_ESCOLA == 27029930 ~ "Escola 3",
  ID_ESCOLA == 26054094 ~ "Escola 4") )
  

model = PROFICIENCIA_LP_SAEB ~ CE
lm1 <- escolas %>% filter(Escolas == "Escola 1") %>%  lm(data=.,model)
lm2 <- escolas %>% filter(Escolas == "Escola 2") %>%  lm(data=.,model)
lm3 <- escolas %>% filter(Escolas == "Escola 3") %>%  lm(data=.,model)
lm4 <- escolas %>% filter(Escolas == "Escola 4") %>%  lm(data=.,model)
lm <- lm(data=escolas,model)

saeb$ID_ESCOLA <- as.character(saeb$ID_ESCOLA) # For graphs

par(mfrow=c(2,2))

escola1 <- escolas %>% filter(Escolas == "Escola 1")
plot(y=escola1$PROFICIENCIA_LP_SAEB,x=escola1$CE,
     col="chartreuse",pch=19,
     ylim = c(100,500),xlim=c(0,3),
     ylab = "Proficiência LP",xlab = "Capital Econômico",
     main = "Escola 1")
abline(lm1,col="steelblue",lty=2)
abline(lm,col="red",lty=1,cex=1.2)
text(x = 2.5,y = 450, labels=paste0(
  "Fixed intercept = 237.90 \n Random intercept =",round(lm1$coefficients[[1]],2),
  " \n Fixed effect = 17.43 \n Random effect = ",round(lm1$coefficients[[2]],2)),
  cex=0.8,col="black")

escola2 <- escolas %>% filter(Escolas == "Escola 2")
plot(y=escola2$PROFICIENCIA_LP_SAEB,x=escola2$CE,
     col="red",pch=15,
     ylim = c(100,500),xlim=c(0,3),
     ylab = "Proficiência LP",xlab = "Capital Econômico",
     main = "Escola 2")
abline(lm2,col="steelblue",lty=2)
abline(lm,col="red",lty=1,cex=1.2)
text(x = 2.5,y = 450, labels=paste0(
  "Fixed intercept = 237.90 \n Random intercept =",round(lm2$coefficients[[1]],2),
  " \n Fixed effect = 17.43 \n Random effect = ",round(lm2$coefficients[[2]],2)),
  cex=0.8,col="black")

escola3 <- escolas %>% filter(Escolas == "Escola 3")
plot(y=escola3$PROFICIENCIA_LP_SAEB,x=escola3$CE,
     col="red",pch=17,
     ylim = c(100,500),xlim=c(0,3),
     ylab = "Proficiência LP",xlab = "Capital Econômico",
     main = "Escola 3")
abline(lm3,col="steelblue",lty=2)
abline(lm,col="red",lty=1,cex=1.2)
text(x = 2.5,y = 450, labels=paste0(
  "Fixed intercept = 237.90 \n Random intercept =",round(lm3$coefficients[[1]],2),
  " \n Fixed effect = 17.43 \n Random effect = ",round(lm3$coefficients[[2]],2)),
  cex=0.8,col="black")

escola4 <- escolas %>% filter(Escolas == "Escola 4")
plot(y=escola4$PROFICIENCIA_LP_SAEB,x=escola4$CE,
     col="blue",pch=23,
     ylim = c(100,500),xlim=c(0,3),
     ylab = "Proficiência LP",xlab = "Capital Econômico",
     main = "Escola 4")
abline(lm4,col="steelblue",lty=2)
abline(lm,col="red",lty=1,cex=1.2)
text(x = 2.5,y = 450, labels=paste0(
  "Fixed intercept = 237.90 \n Random intercept =",round(lm4$coefficients[[1]],2),
  " \n Fixed effect = 17.43 \n Random effect = ",round(lm4$coefficients[[2]],2)),
  cex=0.8,col="black")
dev.off()
```


P é uma medida de proporção de variação na variável dependente que ocorre entre os grupos ( _between_ ) _versus_ a variação dentre os grupos ( _within_ ).

p = t2 / (t2 + o2)

t2 = variância na população entre os clusters ( _between_ )
o2 = variância na população dentre os clusters ( _within_ )

Quando a distância dentre os clusters é maior, mais da variância é explicada pelos clusters.
Quando a distância dentre os clusters é menor, menos da variância é explicada pelos clusters. No limite, há sobreposição entre os clusters (o2 = 0) e a inclusão da informação sobre os grupos não explica nada da variância.

```{r message=F,warning=FALSE}
escolas %>% ggplot(aes(x=PROFICIENCIA_LP_SAEB,fill=Escolas))+
  geom_density()+
  scale_x_continuous(limits = c(100,500),name="Proficiência LP",
                     breaks = seq(0,500,100),expand = c(0,0))+
  scale_y_continuous(limits = c(0,0.015),name="Densidade",expand = c(0,0))+
  theme_classic()
```

Nas quatro escolas selecionadas acima, ainda que a seleção tenha considerado o contraste pelo efeito do coeficiente de inclinação da variável Capital Econômico, vemos que há uma relativa sobreposição na variabilidade da proficiência (variável de interesse), o que nos leva à hipótese de que pouco da variabilidade é explicada pelas escolas.

Nessa base de dados temos a informação dos alunos aninhada com a da turma, da escola, do município e da dependência administrativa.

Estimamos os parâmetros de variância ( _between_ e _within_ ) podem ser estimados por:

```{r message=F,warning=FALSE}
C = nrow(clusters_data)   # n de clusters
N = nrow(data)            # n total de indivíduos
n = clusters_data$n       # n de indivíduos por cluster/tamanho do cluster
S_LP = clusters_data$S_LP # variância por cluster
S_MT = clusters_data$S_MT 
me_tot_LP = mean(data$PROFICIENCIA_LP_SAEB,na.rm=T)
me_tot_MT = mean(data$PROFICIENCIA_MT_SAEB,na.rm=T)
me_LP = clusters_data$me_LP
me_MT = clusters_data$me_MT

# Variance within schools (clusters)
o_hat = sum( ( (n - 1)*S_LP),na.rm = T ) / (N - C)

# variables
n_tiu = (1 / (C-1) ) * ( N - (sum(n^2)/N) )

# Total variance
S_b = sum ( n * ( (me_LP - me_tot_LP)^2 ) ) / (n_tiu*(C-1)) 

# variation between schools (clusters)
t_hat = S_b - (o_hat/n_tiu)

# measure of p
p = t_hat / (t_hat + o_hat)

# O resultado indica que há uma correlação alta entre a proficiência dos alunos
# entre escolas. Podemos interpretar este valor como a proporção da variação
# das proficiências que é explicada pelas escolas.
```

Antes de avançarmos aos MLM, vamos retomar os modelos lineares sem níveis.

y = b0 + b1*x + e

Uma variável dependente é dada em função de uma variável independente _x_, multiplicada por um coeficiente _b1_, somada a um intercepto _b0_ e a um termo de erro (variação aleatória) _e_.

O intercepto ( _b0_ ) é a média condicional de _y_ / _x_ quando x = 0.

```{r message=F,warning=FALSE}
x = rnorm(mean=1.5,sd=0.5,100)
e = rnorm(mean=0,sd=10,100)

y = 220 + 12*x + e

summary( lm(y ~ x) )

reg <- summary( lm(data=data,PROFICIENCIA_LP_SAEB ~ CE) )
b0 = reg$coefficients[1,1]
b1 = reg$coefficients[2,1]
e  = reg$residuals

y = b0 + b1*data$CE + e

```

Em modelos lineares de um nível, temos apenas um intercepto que é comum a todos os indivíduos da população de interesse. Porém, quando os indivíduos são clusterizados há interceptos para cada cluster, i.e. há diferentes médias quando x=0.

Saber se há diferentes médias entre os clusters é uma questão empírica.

É possível também que os coeficientes variam entre clusters.

Temos, portanto, coeficientes e interceptos específicos para cada grupo:

yij = b0j + b1j*x + eij

```{r message=F,warning=FALSE}
cluster_1 <- data %>% filter(ID_ESCOLA == 11002018)
reg <- summary( lm(data=cluster_1,PROFICIENCIA_LP_SAEB ~ CE) )

b0j <- reg$coefficients[1,1]
b1j <- reg$coefficients[2,1]
eij <- reg$residuals
x   <- cluster_1$CE

yij = b0j + b1j*x + eij
```

Comecemos a estimar os coeficientes.

O intercepto de cada grupo pode ser estimado pela média geral da variável dependente (y00) somado a um termo de variação de cada cluster (U00) em relação à média.

B0j = y00 + U00

y00: efeito fixo porque permanece constante entre clusters
general mean value for y when x is 0 for all individuals in the population

U00: efeito aleatório pois varia de cluster para cluster.
deviation between the overall mean and the cluster-specific effects for the intercept

em modelos multiníveis, não estamos apenas interessado na média geral de Y (Y00), mas na variação entre a média geral e o efeito específico dos clusters no intercepto.

O efeito aleatório dos clusters (U00) é muito similar ao termo de erro do modelo linear com um nível. Conforme o efeito dos clusters cresce, aumenta a parte da variação de y explicada por eles, i.e., há fatores nos clusters que explicam y.

assumimos que o termo U0j é aleatório na população, com média=0 (lembre que U0j é um desvio do efeito fixo y00) e variância τ2.

Assumimos que as variâncias τ2 e σ2 não são correlacionadas.

A variância do termo U00 (τ2) também pode ser lida como o impacto do cluster na variável dependente.

Se substituírmos os termos na equação (b0 por y00 + U0j), temos:

y = (y00 + U0j) + b1x + e

Em geral, começamos nossa análise com um modelo simples do intercepto:

yij = y00 + U0j + eij

```{r message=F,warning=FALSE}
y00 = mean(data$PROFICIENCIA_LP_SAEB,na.rm = T)
U0j = y00 - clusters_data$me_LP

clusters_data$U0j <- U0j
data <- merge(data,clusters_data,by = "ID_ESCOLA",all.x = T)

eij <- data %>% group_by(ID_ESCOLA) %>% summarise(
  eij = PROFICIENCIA_LP_SAEB - (y00 + U0j),
  me_eij = mean(eij)
)

data$eij <- eij$eij

cluster_1 <- data %>% filter(ID_ESCOLA == 11002018)

yij = y00 + cluster_1$U0j + cluster_1$eij
cluster_1$PROFICIENCIA_LP_SAEB

```

Nosso objetivo é saber quanto da variância de y está sendo explicada pela variação os indivíduos (σ2) e os clusteres (τ2).

A variação total de y é uma soma simples da variação dos clusteres (τ2) e dos indivíduos (σ2).

### Estimando o coeficiente de inclinação

Se adicionarmos uma única variável preditora (xij) ao nível do indivíduo (nível 1) no modelo, obtemos:

yij = y00 + y10xij + U0j + eij

Este modelo pode ser expresso em dois níveis separados:

###### Nível 1
yij = b0j + b1j*x + eij

##### Nível 2
b0j = Y00 + U0j
b1j = Y10

O subescrito 10 significa que está no nível 1 (indivíduo)

Podemos estimar ρI como antes, embora agora reflita a correlação entre indivíduos do mesmo cluster após controlar por uma variável independente _x_. Neste modelo, γ10 e γ00 possuem efeitos fixos, enquanto σ2 e
τ2 permanecem aleatórios.

γ10 é a média da correlação entre x e y entre os clusteres, e U1j é a variação específica nos clusteres da relação entre as duas variáveis.

interpretamos γ10 da mesma forma que β1 no modelo linear de um nível; i.e. a medida do impacto em y da mudança de 1 unidade em x.

O efeito específico dos clusteres deve ter média próxima de 0 e variar aleatóriamente ao redor de Y10. O modelo com a inclinação aleatória é:

yij = y00 + y10xij + U0j + U1jxij + eij

(y00 + y10xij): efeitos fixos

(U0j + U1jxij): efeitos aleatórios

A variação de y pode ser explicada por diferentes fontes fixas e aleatórias. Na prática, buscamos estimar todas as fontes de variabilidade em um único modelo.

Para diferenciar entre as duas fontes de variância entre-clusters, denotamos a variância de U0j como t02 e de U1j como t12.

```{r message=F,warning=FALSE}
y00 <- mean(coef$b0)
y10 <- mean(coef$b1,na.rm = T)

U0j <- coef$b0 - y00
U1j <- coef$b1 - y10

table_2 %>% sum( (.$Uj1 - mean(.$U1j,na.rm=T))^2 )/ 5 - 1
```

É possível estimar a variância associada ao U1j e ao U0j, respectivamente, t02 e t12.

Centering: centralizar os valores na média é subtrair a média de uma variável em cada valor individual. Isso implica na média do valor centralizado igual à zero, e que cada indivíduo representa um desvio em relação à média.

Em regressões, a centralização é geralmente utilizada para reduzir colinearidade causada por interações entre os termos do modelo.

A abordagem mais comum é subtrair os valores dos indivíduos da média geral (grande média)

Such issues are also important to consider in MLMs, in which interactions are frequently employed. In addition, centering is also a useful tool for avoiding collinearity caused by highly correlated random intercepts and slopes in MLMs (Wooldridge, 2004).
This grand mean centering is certainly the most commonly used in practice (Bickel, 2007).

```{r message=F,warning=FALSE}
gm <- d$PROFICIENCIA_LP_SAEB - mean(d$PROFICIENCIA_LP_SAEB,na.rm = T)
```

Contudo, esta não é a única forma de centralizar uma variável. Outra alternativa conhecida por _group mean centering_ é centralizar os valores em relação às médias dos grupos (clusters) aos quais os indivíduos pertencem.

```{r message=F,warning=FALSE}
gmc <- d %>% group_by(ID_ESCOLA) %>% summarise(
  gmc = PROFICIENCIA_LP_SAEB - mean(PROFICIENCIA_LP_SAEB,na.rm=T),
)
```

By using grand mean centering, we are implicitly comparing individuals to one another (in the form of the overall mean) across the entire sample. On the other hand, when using group mean centering, we are placing each individual in their relative position on x within their cluster.

in this book, he use _grand mean centering_ by default, per recommendations by Hox (2002), among others.

Quando discutimos a estimação dos parâmetros na regressão, fazemos com o método dos mínimos quadrados ordinário (Ordinare Least Squares - OLS). Quando usamos modelos mais complexos, porém, é recomendado o uso de outros métodos, como _Maximum Likelihood Estimation (MLE)_ e _Restricted Maximum Likelihood (REML)_.

Pressupostos ( _assumptions_ ):

1. Os resíduos são independentes.
we assume that the level-2 residuals are independent between clusters.
The random intercept and slope(s) at level 2 are independent of one another across clusters.

2. Os interceptos e coef. do nível 2 são independentes dos resíduos do nível 1.
Level 2 intercepts and coefficients are assumed to be independent of the level-1 residuals

3. Os resíduos do nível 1 são distribuídos como uma normal e têm variância constante.
the level-1 residuals are normally distributed and have a constant variance (homocedasticity)

4. the level-2 intercept and slope(s) have a multivariate normal distribution with a constant covariance matrix

### Síntese

#### MLM com dois níveis

yij = Y00 + Y10xij + U0j + U1jxij + eij

Neste modelo, temos uma variável dependente com index do indivíduo (i) e do cluster (j), que é dada em função de uma variável independente (x), e os termos de erro para ambos os níveis (cluster e indivíduo). Podemos complexificar este modelo agregando múltiplas variáveis em ambos ou mais níveis.

As duas partes deste modelo são explicadas por:

yij = b0 j + b1jxij + eij

bhj = Yh0 + Yhlzj + Uhj

Podemos combinar ambas as equações em uma só:

yij = Y00 + Y10xij + Y01Zj + Y1001xijZj + U0 j + U1jXij + eij

γ00: é o intercepto ou a grande média do modelo
γ10: é o efeito fixo da variável x em y
U0j: representa a variação aleatória para o intercepto dentre os grupos
U1j: representa a variação aleatória da inclinação dentre os grupos. 

As partes adicionais na equação são:
γ01: representa o efeito fixo da variável z no nível 2
γ11: representa a inclinação e o valor da média de x para a escola.

O novo termo no modelo é a interação entre os níveis:
γ1001xijzj = Y10xij * Y01Zj

### Modelos com três ou mais níveis

Estes são modelos complexos e é difícil encontrar estrutura de dados para esta aplicação. Envolvem múltiplas equações e variáveis entre os níveis.

No modelo com três níveis, por exemplo, temos:

yijk = b0jk + b1jkXijk + eijk

No modelo acima foi adicionado o índice (k) da terceira variável subescrito às variáveis e ao termo de erro.

Level 2:
b0jk = Y00k + U0jk
b1jk = Y10k + U1jk

Level 3:
Y00k = d000 +V00k
Y10k = d100 +V10k

We can then use simple substitution to obtain the expression for the level-1 intercept and slope in terms of both level-2 and level-3 parameters.

b0jk = (d000 +V00k) + U0jk

b1jk = (d100 +V10k) + U1jk

Estes termos também podem ser substituídos na equação para obter o modelo completo:

yijk = d000 +V00k + U0 jk + (d100 +V10k + U1jk )xijk + eijk

### Modelos Multiníveis com o pacote *lme4*

A principal biblioteca para a aplicação de modelos multiníveis está no pacote *lme4*, de uso similar ao das funções de modelos lineares do R base.

Como nos modelos lineares comuns, os únicos comandos necessários são para os efeitos fixos e os efeitos aleatórios.


Passo 1. Modelos nulos

Os modelos nulos não contém variáveis independentes e são úteis para estimar a variância do resíduo e do intercepto quando apenas os clusteres são informados.

```{r message=F,warning=FALSE}
# Modelo nulo apenas com o cluster nível 2 (escola)
model1.0 <- lmer(data=data,PROFICIENCIA_LP_SAEB ~ 1 + (1|ID_ESCOLA))
summary(model1.0)

t_hat_0 = 359.1   # variance between clusters
o_hat_0 = 1942.4  # variance within clusters

p_hat = t_hat_0 / (t_hat_0 + o_hat_0)

# We interpret this value to mean that the correlation of reading test scores
# among students within the same schools is approximately 0.16.
```

O modelo nulo informa as variâncias entre indivíduos (o^2) e entre os clusteres (t^2). Estes valores podem ser usados para estimar p (proporção de variação na variável dp. que ocorre entre os grupos _versus_ a variação total)

```{r message=F,warning=FALSE}
# Modelo 1 com variáveis independentes relacionadas aos indivíduos
model1.1 <- lmer(data=data,PROFICIENCIA_LP_SAEB ~ CE + educMae + educPai + sexo + raca + trabFora + regiao + ID_LOCALIZACAO + fluxo + (1|ID_ESCOLA))
summary(model1.1)

t_hat_1 = 191.3   # variance between school
o_hat_1 = 1709.1  # variance within school

Y00 = 226.52937 # Média geral

# Note que reduzimos a variação aleatória das Escolas e dos alunos
```

No modelo 1 adicionamos variáveis independentes aos indivíduos para analisar tanto os efeitos fixos (dos indivíduos) quanto os efeitos aleatórios (do cluster).

A interpretação dos efeitos fixos é a mesma dos modelos lineares de um nível.

Com o modelo hierarquico, podemos saber também quanto da variação da variável de interesse está sendo explicada pelo cluster (escolas). Os resultados mostram que, após considerar o impacto dos efeitos fixos (controles), a variância entre ( _between_ ) escolas é de 191.3 e dentre ( _within_ ) as escolas é de 1709.1.

```{r message=F,warning=FALSE}
# Finally, it is possible to estimate the proportion of variance in the outcome
# variable that is accounted for at each level of the model. In Chapter 1, we
# saw that with single-level OLS regression models, the proportion of response
# variable variance accounted for by the model is expressed as R2. In the context
# of multilevel modeling, R2 values can be estimated for each level of the
# model (Snijders and Bosker, 1999). For level 1, we can calculate:

# R2 nível 1 (indivíduos)
R2_lv1 = 1 - (o_hat_1 + t_hat_1) / (o_hat_0 + t_hat_0)

# Este resultado mostra que o nível 1 explica aproximadamente 0.17 da variação de y

# R2 nível 2 (escolas)
B = mean(clusters$n)

R2_lv2 = 1 - ( o_hat_1 / (B + t_hat_1) ) / (o_hat_0 / (B + t_hat_0))
```

```{r message=F,warning=FALSE}
# Modelo 2 com variáveis independentes relacionadas às escolas
model1.2 <- lmer(data=data,PROFICIENCIA_LP_SAEB ~ CE + educMae + educPai + sexo + raca + trabFora + regiao + ID_LOCALIZACAO + fluxo + estruturaEscola + PC_FORMACAO_DOCENTE + depAdmin + (1|ID_ESCOLA))
summary(model1.2)

t_hat_2 = 179.3   # variance between school
o_hat_2 = 1713.8  # variance within school

# R2 nível 1 (indivíduos)
R2_lv1.2 = 1 - (o_hat_2 + t_hat_2) / (o_hat_0 + t_hat_0)

# R2 nível 2 (escolas)
B = mean(clusters$n)

R2_lv2.2 = 1 - ( o_hat_2 / (B + t_hat_2) ) / (o_hat_0 / (B + t_hat_0))
```

```{r message=F,warning=FALSE}
# Modelo 3 com mais níveis
model1.3 <- lmer(data=data,PROFICIENCIA_LP_SAEB ~ CE + educMae + educPai + sexo + raca + trabFora + regiao + ID_LOCALIZACAO + fluxo + estruturaEscola + PC_FORMACAO_DOCENTE + (1|ID_ESCOLA/ID_TURMA))
summary(model1.3)

```

